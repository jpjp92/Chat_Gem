# app.py: Streamlit App for Gemini AI Interactions

import sys
import os
import time
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ========== Playwright ì´ˆê¸°í™” (Streamlit Cloud í™˜ê²½ ì§€ì›) ==========
try:
    from config import playwright_setup
except Exception as e:
    print(f"ê²½ê³ : Playwright ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
# ====================================================================

# Set library imports
from config.imports import *
from datetime import timezone

# Set environment variables
from config.env import GEMINI_API_KEY, SUPABASE_URL, SUPABASE_KEY

# Set custom CSS for styling
from config.style import GEMINI_CUSTOM_CSS

# Set CSS for login page
from config.logincss import TRENDY_LOGIN_CSS

# Import lang module for multi-language support
from config.lang import (
    get_text,
    get_language_options,
    get_example_inputs,
    get_welcome_message,
    get_lang_code_from_option,
    is_supported_language,
    SUPPORTED_LANGUAGES,
    detect_language,
    handle_language_switching,
    detect_dominant_language,
    get_usage_status_info
)

# Set prompts and functions for Gemini interactions
from config.prompts import (
    get_system_prompt,
    analyze_image_with_gemini_multiturn,
    analyze_youtube_with_gemini_multiturn,
    summarize_webpage_with_gemini,
    analyze_pdf_with_gemini_multiturn,
    summarize_webpage_with_gemini_multiturn,
)

# Set storage utilities for Supabase
from config.storage_utils import (
    upload_image_to_supabase,
    upload_pdf_to_supabase,
    save_chat_history_to_supabase,
    load_chat_history_from_supabase,
    get_chat_sessions_from_supabase,
)

# Set utility functions for handling various tasks
from config.utils import (
    extract_video_id,
    is_youtube_url,
    extract_urls_from_text,
    is_youtube_summarization_request,
    is_url_summarization_request,
    is_pdf_url,
    is_pdf_summarization_request,
    fetch_webpage_content,
    fetch_pdf_text,
    analyze_youtube_with_gemini,
    extract_webpage_metadata,
    is_image_analysis_request,
    is_pdf_analysis_request,
    create_summary,
)

# Import validators
from config.validators import (
    validate_nickname,
    validate_image_file,
    validate_pdf_file,
    process_image_for_gemini,
)
import pandas as pd

# F1 intent / scraper / i18n helpers
try:
    from config.intents import detect_f1_intent, detect_f1_intent_scored
    from config.scrapers.f1_scraper import fetch_drivers
    from config.i18n import localize_headers
except Exception as e:
    # Fail-safe: importing these should not break app if files missing during development
    logger.warning(f"F1 helper modules import warning: {e}")
    def detect_f1_intent(text):
        return None
    def detect_f1_intent_scored(text, threshold=1.8):
        return None
    def fetch_drivers(year, max_length=5000, timeout=15):
        return {"success": False, "error": "f1 scraper not available"}
    def localize_headers(headers, lang):
        return headers

# Supabase cache helpers (optional - config/cache_utils may implement these)
try:
    from config.cache_utils import (
        load_cached_drivers_supabase,
        save_cached_drivers_supabase,
        is_cache_fresh_supabase,
    )
except Exception:
    def load_cached_drivers_supabase(year):
        return None
    def save_cached_drivers_supabase(year, rows, meta):
        return None
    def is_cache_fresh_supabase(year, ttl_seconds=3600):
        return False

# Import usage manager
from config.usage_manager import (
    get_usage_count,
    increment_usage,
)

# Import session manager
from config.session_manager import initialize_session_state, create_new_chat_session, save_current_session, load_session, delete_session, export_chat_session

# Login UI moved to config/login_html.py
from config.login_html import show_login_page, create_or_get_user

# Import API manager for web search
from config.api_manager import initialize_apis

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Supabase client initialization
# Supabase: `config.imports` provides a LazySupabase instance named `supabase`.
# Avoid creating a real client at import time to prevent network calls during
# Streamlit cold starts (especially on mobile). The LazySupabase will
# initialize the real client on first use.
try:
    if SUPABASE_URL and SUPABASE_KEY:
        logger.info("Supabase configured for lazy initialization")
    else:
        logger.warning("Supabase í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½")
except Exception as e:
    logger.error(f"Supabase ì—°ê²° ì´ˆê¸°í™” ê²½ê³ : {e}")

# Page configuration  
st.set_page_config(
    page_title="Chat with Gemini",
    page_icon="âœ¨",
    layout="wide",
)

# Apply custom CSS
st.markdown(GEMINI_CUSTOM_CSS, unsafe_allow_html=True)

# NOTE: GEMINI API key configuration is moved into `main()` to avoid
# running network-sensitive initialization at import time which can
# delay the initial Streamlit load (especially on mobile or cold starts).

# `create_or_get_user` and `show_login_page` moved to `config/login.py`

def detect_response_language(user_input: str, system_language: str) -> str:
    """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì‘ë‹µ ì–¸ì–´ë¥¼ ê°ì§€í•©ë‹ˆë‹¤ (í•œêµ­ì–´/ì˜ì–´/ìŠ¤í˜ì¸ì–´ ì§€ì›)"""
    user_input_lower = user_input.lower().strip()
    
    # 1. ëª…ì‹œì  ì–¸ì–´ ìš”ì²­ ê°ì§€ 
    if any(phrase in user_input_lower for phrase in ["í•œêµ­ì–´ë¡œ", "in korean", "en coreano"]):
        return "ko"
    elif any(phrase in user_input_lower for phrase in ["in english", "ì˜ì–´ë¡œ", "en inglÃ©s"]):
        return "en"  
    elif any(phrase in user_input_lower for phrase in ["in spanish", "ìŠ¤í˜ì¸ì–´ë¡œ", "en espaÃ±ol"]):
        return "es"
    
    # 2. ìŠ¤í˜ì¸ì–´ í‚¤ì›Œë“œ ê°•ë ¥ ê°ì§€
    spanish_keywords = [
        'analizar', 'describir', 'explicar', 'quÃ©', 'cÃ³mo', 'cuÃ¡ndo', 'dÃ³nde', 'por quÃ©',
        'mostrar', 'decir', 'hola', 'gracias', 'por favor', 'imagen', 'foto', 'resumir',
        'video', 'pÃ¡gina', 'documento', 'ayuda', 'puedes', 'podrÃ­as', 'sÃ­', 'no'
    ]
    
    # 3. ì˜ì–´ í‚¤ì›Œë“œ ê°•ë ¥ ê°ì§€  
    english_keywords = [
        'analyze', 'describe', 'explain', 'what', 'how', 'when', 'where', 'why',
        'show', 'tell', 'please', 'can', 'could', 'would', 'should', 'image',
        'picture', 'photo', 'help', 'hello', 'yes', 'no', 'summarize'
    ]
    
    # ì…ë ¥ì´ ëŒ€ë¶€ë¶„ íŠ¹ì • ì–¸ì–´ ë‹¨ì–´ë¡œ êµ¬ì„±ëœ ê²½ìš°
    words = user_input_lower.split()
    if len(words) >= 2:  # ìµœì†Œ 2ë‹¨ì–´ ì´ìƒ
        # ìŠ¤í˜ì¸ì–´ í‚¤ì›Œë“œ ì²´í¬
        spanish_count = sum(1 for word in words if word in spanish_keywords)
        if spanish_count / len(words) >= 0.6:  # 60% ì´ìƒì´ ìŠ¤í˜ì¸ì–´ í‚¤ì›Œë“œ
            logger.info(f"ìŠ¤í˜ì¸ì–´ í‚¤ì›Œë“œ ê°ì§€: {spanish_count}/{len(words)} words")
            return "es"
            
        # ì˜ì–´ í‚¤ì›Œë“œ ì²´í¬
        english_count = sum(1 for word in words if word in english_keywords)
        if english_count / len(words) >= 0.6:  # 60% ì´ìƒì´ ì˜ì–´ í‚¤ì›Œë“œ
            logger.info(f"ì˜ì–´ í‚¤ì›Œë“œ ê°ì§€: {english_count}/{len(words)} words")
            return "en"
    
    # 4. ë¬¸ì ì²´ê³„ ê°ì§€
    has_korean = bool(re.search(r'[ê°€-í£]', user_input))
    has_spanish_chars = bool(re.search(r'[Ã±Ã¡Ã©Ã­Ã³ÃºÃ¼Â¿Â¡]', user_input))  # ìŠ¤í˜ì¸ì–´ íŠ¹ìˆ˜ë¬¸ì
    has_english_letters = bool(re.search(r'[a-zA-Z]', user_input))
    
    if has_spanish_chars:
        logger.info(f"ìŠ¤í˜ì¸ì–´ íŠ¹ìˆ˜ë¬¸ì ê°ì§€: '{user_input}'")
        return "es"
    elif has_english_letters and not has_korean and len(user_input.strip()) > 5:
        logger.info(f"ì˜ì–´ ì „ìš© ì…ë ¥ ê°ì§€: '{user_input}'")
        return "en"
    
    # 5. detect_dominant_language í•¨ìˆ˜ ì‚¬ìš©
    detected_lang, confidence = detect_dominant_language(user_input, system_language)
    
    # 6. ê°ì§€ëœ ì–¸ì–´ê°€ ë‹¤ë¥´ê³  ì‹ ë¢°ë„ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì–¸ì–´ë¡œ ì‘ë‹µ
    if detected_lang != system_language and confidence >= 0.4:
        logger.info(f"ì–¸ì–´ ê°ì§€ ê²°ê³¼: {detected_lang}, ì‹ ë¢°ë„: {confidence:.2f}")
        return detected_lang
    
    # 7. ê·¸ ì™¸ì˜ ê²½ìš°: ì‹œìŠ¤í…œ ì–¸ì–´ ì‚¬ìš©
    return system_language

def create_model_for_language(language: str):
    """íŠ¹ì • ì–¸ì–´ì— ë§ëŠ” Gemini ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤"""
    # Ensure genai is configured before creating model (lazy init)
    try:
        ensure_genai_configured()
    except NameError:
        # If function not yet defined (shouldn't happen), skip and rely on main() configuration
        pass
    system_prompt = get_system_prompt(language)
    safety_settings = {
        'HARASSMENT': 'BLOCK_NONE',
        'HATE_SPEECH': 'BLOCK_NONE',
        'SEXUALLY_EXPLICIT': 'BLOCK_NONE',
        'DANGEROUS': 'BLOCK_NONE',
    }
    
    # ì–¸ì–´ë³„ ì‘ë‹µ ê°€ì´ë“œë¼ì¸ (ê° ì–¸ì–´ë¡œ ì‘ì„±)
    language_names = {
        "ko": "í•œêµ­ì–´",
        "en": "English", 
        "es": "espaÃ±ol"
    }
    
    # ì–¸ì–´ë³„ ê°€ì´ë“œë¼ì¸ êµ¬ì„±
    if language == "ko":
        language_guide = """ì‚¬ìš©ìì˜ ì…ë ¥ ì–¸ì–´ë‚˜ ëª…ì‹œì  ìš”ì²­ì— ë”°ë¼ ì ì ˆí•œ ì–¸ì–´ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
- ì‚¬ìš©ìê°€ í•œêµ­ì–´ë¡œ ì…ë ¥í•˜ë©´ í•œêµ­ì–´ë¡œ ì‘ë‹µ
- ì‚¬ìš©ìê°€ ì˜ì–´ë¡œ ì…ë ¥í•˜ë©´ ì˜ì–´ë¡œ ì‘ë‹µ  
- ì‚¬ìš©ìê°€ ìŠ¤í˜ì¸ì–´ë¡œ ì…ë ¥í•˜ë©´ ìŠ¤í˜ì¸ì–´ë¡œ ì‘ë‹µ
- ëª…ì‹œì ì¸ ì–¸ì–´ ìš”ì²­ì´ ìˆìœ¼ë©´ í•´ë‹¹ ì–¸ì–´ë¡œ ì‘ë‹µ

ê¸°ë³¸ ì„ í˜¸ ì–¸ì–´ëŠ” í•œêµ­ì–´ì…ë‹ˆë‹¤."""
    elif language == "es":
        language_guide = """Responde en el idioma apropiado segÃºn la entrada del usuario o solicitud explÃ­cita.
- Si el usuario escribe en coreano, responde en coreano
- Si el usuario escribe en inglÃ©s, responde en inglÃ©s
- Si el usuario escribe en espaÃ±ol, responde en espaÃ±ol
- Si hay una solicitud explÃ­cita de idioma, responde en ese idioma

El idioma preferido por defecto es espaÃ±ol."""
    else:  # English
        language_guide = """Please respond in the appropriate language based on user input or explicit request.
- If the user inputs in Korean, respond in Korean
- If the user inputs in English, respond in English
- If the user inputs in Spanish, respond in Spanish
- If there's an explicit language request, respond in that language

The default preferred language is English."""
    
    system_prompt_with_lang = f"""{system_prompt}

{language_guide}"""
    
    return genai.GenerativeModel('gemini-2.5-flash', system_instruction=system_prompt_with_lang, safety_settings=safety_settings)


def ensure_genai_configured():
    """Lazy initialization for genai configuration. Safe to call multiple times."""
    # Use a module-level flag to avoid reconfiguring
    if getattr(sys.modules[__name__], "_genai_configured", False):
        return

    if not GEMINI_API_KEY:
        logger.warning("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. genai êµ¬ì„± ê±´ë„ˆëœ€.")
        return

    try:
        start = time.perf_counter()
        genai.configure(api_key=GEMINI_API_KEY)
        elapsed = time.perf_counter() - start
        setattr(sys.modules[__name__], "_genai_configured", True)
        logger.info(f"genai lazy êµ¬ì„± ì™„ë£Œ (configure took {elapsed:.4f}s)")
    except Exception as e:
        logger.error(f"genai.configure ì‹¤íŒ¨: {e}")
        # don't raise - ensure caller can handle absence of configured genai
        return

def show_chat_dashboard():
    """ê¸°ì¡´ ì±„íŒ… ëŒ€ì‰¬ë³´ë“œ í‘œì‹œ (ë‹¤êµ­ì–´ ì ìš©)"""
    lang = st.session_state.system_language
    logger.info(f"System language: {lang}")
    
    # ê¸°ë³¸ ëª¨ë¸ ìƒì„±
    model = create_model_for_language(lang)

    with st.sidebar:
        st.header(get_text("settings", lang))
        
        if st.button(
            get_text("new_chat", lang), 
            key="new_chat", 
            help=get_text("new_chat_help", lang), 
            width='stretch'
        ):
            create_new_chat_session()
            st.rerun()
        
        with st.expander(get_text("chat_history", lang), expanded=True):
            if not st.session_state.chat_sessions:
                st.markdown(f"*{get_text('no_chat_history', lang)}*")
            else:
                # datetime ê°ì²´ì˜ timezone ì •ë³´ë¥¼ í†µì¼í•˜ì—¬ ì •ë ¬
                def get_sortable_datetime(session):
                    last_updated = session['last_updated']
                    if isinstance(last_updated, str):
                        try:
                            return datetime.fromisoformat(last_updated.replace('Z', '+00:00'))
                        except (ValueError, TypeError) as e:
                            logger.warning(f"datetime ë³€í™˜ ì‹¤íŒ¨: {str(e)}, ê¸°ë³¸ê°’ ì‚¬ìš©")
                            return datetime.now(timezone.utc)
                    elif hasattr(last_updated, 'replace') and last_updated.tzinfo is None:
                        return last_updated.replace(tzinfo=timezone.utc)
                    else:
                        return last_updated
                
                sorted_sessions = sorted(st.session_state.chat_sessions, 
                                        key=get_sortable_datetime, reverse=True)
                for idx, session in enumerate(sorted_sessions[:5]):
                    is_current = session['id'] == st.session_state.current_session_id
                    title = session['title'][:25] + "..." if len(session['title']) > 25 else session['title']
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        if is_current:
                            st.markdown(f"ğŸ”¸ **{title}**")
                            st.markdown(f"*{session['last_updated'].strftime('%m/%d %H:%M')}*")
                        else:
                            if st.button(f"{title}", key=f"session_{session['id']}", 
                                         help=f"ìƒì„±: {session['created_at'].strftime('%Y-%m-%d %H:%M')}"):
                                load_session(session["id"])
                                st.rerun()
                            st.caption(f"{session['last_updated'].strftime('%m/%d %H:%M')}")
                    with col2:
                        if st.button("ğŸ—‘ï¸", key=f"delete_{session['id']}", 
                                     help="ì´ ì„¸ì…˜ì„ ì‚­ì œí•©ë‹ˆë‹¤"):
                            delete_session(session["id"])
                            st.rerun()
                    if idx < len(sorted_sessions) - 1:
                        st.markdown("---")
                if len(st.session_state.chat_sessions) > 5:
                    st.caption(f"+ {len(st.session_state.chat_sessions) - 5}ê°œ ë”ë³´ê¸°")
        
        with st.expander(get_text("language_selection", lang), expanded=False):
            options, current_index = get_language_options(lang)
            selected_language = st.selectbox(
                get_text("language_label", lang),
                options, 
                index=current_index,
                key="language_select"
            )
            # ì–¸ì–´ ë³€ê²½ ì²˜ë¦¬ (ìˆ˜ë™ ë³€ê²½)
            new_lang = get_lang_code_from_option(selected_language)
            if new_lang != lang:
                st.session_state.system_language = new_lang
                model = create_model_for_language(new_lang)
                # ì±„íŒ… íˆìŠ¤í† ë¦¬ëŠ” ë³´ì¡´í•˜ë˜, ì–¸ì–´ ë³€ê²½ ë©”ì‹œì§€ ì¶”ê°€
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": get_text("language_changed", new_lang)
                })
                st.rerun()
        
        # ì‚¬ìš©ëŸ‰ ìƒíƒœ í‘œì‹œ (ë‹¤êµ­ì–´ ì ìš©)
        with st.expander(get_text("today_usage", lang), expanded=True):
            usage_count = get_usage_count()
            usage_percentage = min(usage_count / 100, 1.0)
            status_info = get_usage_status_info(usage_count, lang)
            
            st.progress(usage_percentage)
            st.markdown(f"""
            <div style='display: flex; justify-content: space-between; align-items: center; padding: 0.5rem 0; font-size: 0.9rem; margin-top: 0.25rem;'>
                <div style='display: flex; align-items: center; gap: 0.25rem;'>
                    <span>{status_info["icon"]}</span>
                    <span style='color: {status_info["color"]}; font-weight: 500;'>{status_info["text"]}</span>
                </div>
                <div style='font-weight: 600; color: var(--text-color, #262730);'>
                    <span style='color: {status_info["color"]};'>{usage_count}</span>
                    <span style='color: var(--text-color-light, #888); font-size: 0.8rem;'> / 100</span>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            if usage_count >= 100:
                st.error(get_text("usage_limit_error", lang), icon="ğŸš«")
            elif usage_count >= 80:
                st.warning(get_text("usage_warning", lang), icon="âš ï¸")
        
        with st.expander(get_text("quick_functions", lang), expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                if st.button(
                    get_text("export", lang), 
                    key="export_quick", 
                    help=get_text("export_help", lang), 
                    width='stretch'
                ):
                    try:
                        export_data = export_chat_session()
                        if export_data:
                            st.download_button(
                                label=get_text("download", lang),
                                data=export_data,
                                file_name=f"chat_{datetime.now().strftime('%m%d_%H%M')}.json",
                                mime="application/json",
                                key="download_json",
                                width='stretch'
                            )
                        else:
                            st.error(get_text("no_export_data", lang))
                    except Exception as e:
                        st.error(get_text("export_failed", lang))
            with col2:
                if st.button(
                    get_text("delete_all", lang), 
                    key="clear_all", 
                        help=get_text("delete_all_help", lang)
                ):
                    if st.session_state.chat_sessions:
                        st.markdown("---")
                        confirm = st.checkbox(get_text("confirm_delete", lang), key="confirm_delete_checkbox")
                        if confirm:
                            col_yes, col_no = st.columns(2)
                            with col_yes:
                                if st.button(get_text("confirm_yes", lang), key="confirm_clear", type="secondary"):
                                    st.session_state.chat_sessions = []
                                    create_new_chat_session()
                                    st.success(get_text("all_chats_deleted", lang))
                                    st.rerun()
                            with col_no:
                                if st.button(get_text("confirm_no", lang), key="cancel_clear"):
                                    st.session_state.confirm_delete_checkbox = False
                                    st.rerun()

        with st.expander(get_text("help_guide", lang), expanded=False):
            st.markdown(f"""
            {get_text("help_basic", lang)}
            {get_text("help_basic_content", lang)}
            
        
            """)

    # ë©”ì¸ í™”ë©´ - í™˜ì˜ ë©”ì‹œì§€ ë° ì˜ˆì‹œ ë²„íŠ¼
    if not st.session_state.messages:
        st.markdown(f"""
        <div class="main-header">
            <h2 class="main-title">{get_text("main_title", lang)}</h2>
            <h5 class="subtitle">{get_text("subtitle", lang)}</h5>
        </div>
        """, unsafe_allow_html=True)
        
        # ì˜ˆì‹œ ì¹´ë“œë“¤ - ëª¨ë˜ ë””ìì¸ (ChatGPT, Grok, Gemini ìŠ¤íƒ€ì¼)
        st.markdown("### ğŸ’¡ " + get_text("try_examples", lang, default="ì‚¬ìš© ì˜ˆì‹œ"))
        
        example_inputs = get_example_inputs(lang)
        
        # ê° ì˜ˆì‹œ ì¹´ë“œ ì •ì˜ (ì•„ì´ì½˜, ì œëª©, ì„¤ëª…)
        examples = [
            {
                "key": "webpage",
                "icon": "ğŸŒ",
                "title": get_text("example_webpage", lang),
                "desc": get_text("example_webpage_help", lang),
                "input": example_inputs["webpage"]
            },
            {
                "key": "youtube",
                "icon": "ğŸ“¹",
                "title": get_text("example_youtube", lang),
                "desc": get_text("example_youtube_help", lang),
                "input": example_inputs["youtube"]
            },
            {
                "key": "pdf",
                "icon": "ğŸ“„",
                "title": get_text("example_pdf", lang),
                "desc": get_text("example_pdf_help", lang),
                "input": example_inputs["pdf"]
            },
            {
                "key": "image",
                "icon": "ğŸ–¼ï¸",
                "title": get_text("example_image", lang),
                "desc": get_text("example_image_help", lang),
                "input": example_inputs["image"]
            },
            {
                "key": "chat",
                "icon": "ğŸ’¬",
                "title": get_text("example_chat", lang),
                "desc": get_text("example_chat_help", lang),
                "input": example_inputs["chat"]
            }
        ]
        
        # ì¹´ë“œ UIë¥¼ Streamlit ë²„íŠ¼ìœ¼ë¡œ êµ¬í˜„
        cols = st.columns(5)
        for col, example in zip(cols, examples):
            with col:
                if st.button(
                    example['title'],
                    key=f"example_{example['key']}",
                    help=example['desc'],
                    use_container_width=True
                ):
                    st.session_state.example_input = example['input']
        
        if "example_input" in st.session_state:
            st.info(get_text("example_input_label", lang, example=st.session_state.example_input))
            del st.session_state.example_input

    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    chat_container = st.container()
    with chat_container:
        if "selected_message" in st.session_state:
            message = st.session_state.selected_message
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                if "images" in message and message["images"]:
                    cols = st.columns(min(3, len(message["images"])))
                    for idx, img_data in enumerate(message["images"]):
                        with cols[idx % 3]:
                            try:
                                if isinstance(img_data, str):
                                    # URLì¸ ê²½ìš° ì§ì ‘ í‘œì‹œ
                                    st.image(img_data, caption=f"ì´ë¯¸ì§€ {idx+1}", width=300)
                                else:
                                    # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ì¸ ê²½ìš°
                                    img = Image.open(io.BytesIO(img_data))
                                    st.image(img, caption=f"ì´ë¯¸ì§€ {idx+1}", width=300)
                            except Exception as e:
                                st.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            if st.button("ì „ì²´ ëŒ€í™” ë³´ê¸°"):
                del st.session_state.selected_message
                st.rerun()
        else:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
                    if "images" in message and message["images"]:
                        cols = st.columns(min(3, len(message["images"])))
                        for idx, img_data in enumerate(message["images"]):
                            with cols[idx % 3]:
                                try:
                                    if isinstance(img_data, str):
                                        # URLì¸ ê²½ìš° ì§ì ‘ í‘œì‹œ
                                        st.image(img_data, caption=f"ì´ë¯¸ì§€ {idx+1}", width=300)
                                    else:
                                        # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ì¸ ê²½ìš°
                                        img = Image.open(io.BytesIO(img_data))
                                        st.image(img, caption=f"ì´ë¯¸ì§€ {idx+1}", width=300)
                                except Exception as e:
                                    st.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

    # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ (ë‹¤êµ­ì–´ ì ìš©)
    with st.container():
        with st.expander(get_text("attachments", lang), expanded=False):
            uploaded_images = st.file_uploader(
                get_text("upload_images", lang),
                type=['png', 'jpg', 'jpeg', 'webp'],
                accept_multiple_files=True,
                key=f"chat_image_uploader_{st.session_state.uploader_key}",
                help=get_text("upload_images_help", lang)
            )
            if uploaded_images:
                st.session_state.uploaded_images = uploaded_images
                st.success(get_text("images_ready", lang, count=len(uploaded_images)))
                cols = st.columns(min(4, len(uploaded_images)))
                for idx, img_file in enumerate(uploaded_images):
                    with cols[idx % 4]:
                        img = Image.open(img_file)
                        st.image(img, caption=f"ì´ë¯¸ì§€ {idx+1}", width=200)
            
            uploaded_pdf = st.file_uploader(
                get_text("upload_pdf", lang),
                type=['pdf'],
                accept_multiple_files=False,
                key=f"chat_pdf_uploader_{st.session_state.uploader_key}",
                help=get_text("upload_pdf_help", lang)
            )
            if uploaded_pdf:
                valid, msg = validate_pdf_file(uploaded_pdf)
                if not valid:
                    st.error(msg)
                else:
                    st.session_state.uploaded_pdf_file = uploaded_pdf
                    st.success(get_text("pdf_ready", lang, name=uploaded_pdf.name))
            
            if st.button(get_text("clear_attachments", lang), key="clear_attachments", use_container_width=False, type="secondary"):
                st.session_state.uploaded_images = []
                st.session_state.uploaded_pdf_file = None
                st.session_state.uploader_key += 1
                st.rerun()

        user_input = st.chat_input(get_text("chat_input_placeholder", lang))
    
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ - ê°œì„ ëœ ì–¸ì–´ ê°ì§€ ë¡œì§ ë° ë™ì  ëª¨ë¸ ìƒì„± ì ìš©
    if user_input:
        save_current_session()
        if not st.session_state.current_session_id:
            create_new_chat_session()

        # ê°œì„ ëœ ì–¸ì–´ ê°ì§€ ë° ì „í™˜ ì²˜ë¦¬
        current_lang = st.session_state.system_language
        new_lang, should_switch = handle_language_switching(user_input, current_lang)
        
        # ì‹œìŠ¤í…œ ì–¸ì–´ ì „í™˜ (UI ì–¸ì–´ ë³€ê²½)
        if should_switch:
            logger.info(f"ì‹œìŠ¤í…œ ì–¸ì–´ ìë™ ì „í™˜: {current_lang} -> {new_lang}")
            st.session_state.system_language = new_lang
            st.session_state.messages.append({
                "role": "assistant",
                "content": get_text("language_changed", new_lang)
            })
        
        # ì‘ë‹µ ì–¸ì–´ ê²°ì • (ì‹¤ì œ ëŒ€í™” ì–¸ì–´)
        response_language = detect_response_language(user_input, st.session_state.system_language)
        logger.info(f"ì‘ë‹µ ì–¸ì–´ ê²°ì •: {response_language}")
        
        # ì‘ë‹µ ì–¸ì–´ì— ë§ëŠ” ëª¨ë¸ ìƒì„±
        response_model = create_model_for_language(response_language)
        
        if get_usage_count() >= 100:
            st.error(get_text("daily_limit_exceeded", response_language))
        else:
            increment_usage()
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            image_data = []
            image_urls = []
            
            if st.session_state.uploaded_images:
                for img_file in st.session_state.uploaded_images:
                    valid, msg = validate_image_file(img_file)
                    if not valid:
                        st.error(msg)
                        continue
                        
                    # ì´ë¯¸ì§€ ë°ì´í„° ì¤€ë¹„ (Gemini APIìš©)
                    img_file.seek(0)
                    img_bytes = img_file.read()
                    image_data.append(img_bytes)
                    
                    # ë¡œê·¸ì¸í•œ ê²½ìš° Supabaseì— ì´ë¯¸ì§€ ì—…ë¡œë“œ
                    if st.session_state.is_logged_in and st.session_state.user_id and supabase:
                        try:
                            # íŒŒì¼ í¬ì¸í„° ì´ˆê¸°í™”
                            img_file.seek(0)
                            # Supabaseì— ì—…ë¡œë“œ
                            image_url = upload_image_to_supabase(img_file, supabase, "chat-images", st.session_state.user_id)
                            if image_url:
                                image_urls.append(image_url)
                                logger.info(f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„±ê³µ: {image_url}")
                            else:
                                logger.error("ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨")
                        except Exception as e:
                            logger.error(f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
                            st.warning(f"ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

            if not st.session_state.messages:
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": get_welcome_message(response_language)
                })
            
            # ë©”ì‹œì§€ ì¶”ê°€ (ì´ë¯¸ì§€ ë°ì´í„°ì™€ URL ëª¨ë‘ ì €ì¥)
            new_message = {
                "role": "user",
                "content": user_input,
                "images": image_data  # Gemini APIìš© ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            }
            
            # ì´ë¯¸ì§€ URLì´ ìˆìœ¼ë©´ ë³„ë„ë¡œ ì €ì¥ (Supabase ì €ì¥ìš©)
            if image_urls:
                new_message["image_urls"] = image_urls
                
            st.session_state.messages.append(new_message)

            is_pdf_request, pdf_url = is_pdf_summarization_request(user_input)
            has_uploaded_pdf = st.session_state.uploaded_pdf_file is not None
            is_pdf_analysis = is_pdf_analysis_request(user_input, has_uploaded_pdf or is_pdf_request)
            is_youtube_request, youtube_url = is_youtube_summarization_request(user_input)
            is_webpage_request, webpage_url = is_url_summarization_request(user_input)
            has_images = len(st.session_state.uploaded_images) > 0
            is_image_analysis = is_image_analysis_request(user_input, has_images)

            with st.status(get_text("processing", response_language), expanded=True) as status:
                if is_pdf_analysis:
                    status.update(label=get_text("processing_pdf", response_language))
                    if has_uploaded_pdf and (not is_pdf_request or st.session_state.current_pdf_url != pdf_url):
                        pdf_file = st.session_state.uploaded_pdf_file
                        pdf_file.seek(0)
                        content, metadata, sections = fetch_pdf_text(pdf_file=pdf_file)
                        st.session_state.current_pdf_url = None  # URLì´ ì—†ìœ¼ë¯€ë¡œ None
                        st.session_state.current_pdf_content = content
                        st.session_state.current_pdf_metadata = metadata
                        st.session_state.current_pdf_sections = sections
                    elif is_pdf_request and st.session_state.current_pdf_url != pdf_url:
                        st.session_state.current_pdf_url = pdf_url
                        st.session_state.current_pdf_content, st.session_state.current_pdf_metadata, st.session_state.current_pdf_sections = fetch_pdf_text(pdf_url=pdf_url)
                    content, metadata, sections = st.session_state.current_pdf_content, st.session_state.current_pdf_metadata, st.session_state.current_pdf_sections
                    if content.startswith("âŒ"):
                        response = content
                    else:
                        chat_session = response_model.start_chat(history=st.session_state.chat_history)
                        pdf_source = pdf_url if pdf_url else (st.session_state.uploaded_pdf_file.name if has_uploaded_pdf else "")
                        response = analyze_pdf_with_gemini_multiturn(content, metadata, user_input, chat_session, response_language, pdf_source, sections)
                        st.session_state.chat_history = chat_session.history
                        
                elif is_youtube_request:
                    status.update(label=get_text("processing_youtube", response_language))
                    try:
                        video_id = extract_video_id(youtube_url)
                        if not video_id:
                            response = "âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ YouTube URLì…ë‹ˆë‹¤."
                        else:
                            # ë©€í‹°í„´ì—ì„œ í•œ ë²ˆì— ëª¨ë“  ì²˜ë¦¬
                            chat_session = response_model.start_chat(history=st.session_state.chat_history)
                            response = analyze_youtube_with_gemini_multiturn(
                                youtube_url,  # URL ì§ì ‘ ì „ë‹¬
                                user_input, 
                                chat_session, 
                                response_language
                            )
                            st.session_state.chat_history = chat_session.history
                    except Exception as e:
                        logger.error(f"ìœ íŠœë¸Œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                        response = f"âŒ ìœ íŠœë¸Œ ë¹„ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        
                elif is_webpage_request:
                    status.update(label=get_text("processing_webpage", response_language))
                    if st.session_state.current_webpage_url != webpage_url:
                        st.session_state.current_webpage_url = webpage_url
                        content = fetch_webpage_content(webpage_url)
                        st.session_state.current_webpage_content = content
                        st.session_state.current_webpage_metadata = extract_webpage_metadata(webpage_url, content)
                    content = st.session_state.current_webpage_content
                    metadata = st.session_state.current_webpage_metadata
                    if content.startswith("âŒ"):
                        response = content
                    else:
                        chat_session = response_model.start_chat(history=st.session_state.chat_history)
                        response = summarize_webpage_with_gemini_multiturn(content, metadata, user_input, chat_session, response_language, webpage_url)
                        st.session_state.chat_history = chat_session.history
                elif is_image_analysis and has_images:
                    status.update(label=get_text("processing_image", response_language))
                    images = [process_image_for_gemini(img) for img in st.session_state.uploaded_images]
                    if all(img is not None for img in images):
                        chat_session = response_model.start_chat(history=st.session_state.chat_history)
                        response = analyze_image_with_gemini_multiturn(images, user_input, chat_session, response_language)
                        st.session_state.chat_history = chat_session.history
                    else:
                        response = "âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                else:
                    status.update(label=get_text("processing_response", response_language))
                    
                    # âœ¨ ë‚ ì”¨ ì¿¼ë¦¬ ìš°ì„  ì²˜ë¦¬ (OpenWeatherMap API)
                    weather_result = None
                    if st.session_state.api_manager:
                        weather_api = st.session_state.api_manager['apis'].get('weather')
                        if weather_api:
                            query_lower = user_input.lower().replace(" ", "")
                            
                            # ë‚ ì”¨ ì¿¼ë¦¬ ê°ì§€
                            if "ë‚ ì”¨" in query_lower or "weather" in query_lower or "tiempo" in query_lower:
                                try:
                                    status.update(label="ğŸŒ¤ï¸ ë‚ ì”¨ ì •ë³´ ì¡°íšŒ ì¤‘...")
                                    
                                    # í•œê¸€-ì˜ì–´ ë„ì‹œëª… ë§¤í•‘
                                    city_mapping = {
                                        "ì„œìš¸": "Seoul", "ë¶€ì‚°": "Busan", "ì¸ì²œ": "Incheon", 
                                        "ëŒ€êµ¬": "Daegu", "ëŒ€ì „": "Daejeon", "ê´‘ì£¼": "Gwangju",
                                        "ì œì£¼": "Jeju", "ì „ì£¼": "Jeonju", "ì¶˜ì²œ": "Chuncheon", 
                                        "ê°•ë¦‰": "Gangneung", "ê²½ê¸°": "Gyeonggi",
                                        "ë„ì¿„": "Tokyo", "ì˜¤ì‚¬ì¹´": "Osaka", "ë² ì´ì§•": "Beijing",
                                        "ìƒí•˜ì´": "Shanghai", "ë‰´ìš•": "New York", "ëŸ°ë˜": "London",
                                        "íŒŒë¦¬": "Paris", "ë² ë¥¼ë¦°": "Berlin", "ë§ˆë“œë¦¬ë“œ": "Madrid",
                                        "ë¡œë§ˆ": "Rome", "ëª¨ìŠ¤í¬ë°”": "Moscow", "ë°©ì½•": "Bangkok",
                                        "ì‹±ê°€í¬ë¥´": "Singapore", "ì‹œë“œë‹ˆ": "Sydney", 
                                        "ë©œë²„ë¥¸": "Melbourne", "í† ë¡ í† ": "Toronto", 
                                        "ë°´ì¿ ë²„": "Vancouver", "ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤": "Los Angeles",
                                        "ì‹œì¹´ê³ ": "Chicago", "ì›Œì‹±í„´": "Washington", 
                                        "ë³´ìŠ¤í„´": "Boston", "ë‘ë°”ì´": "Dubai", "í™ì½©": "Hong Kong"
                                    }
                                    
                                    # ë„ì‹œëª… ì¶”ì¶œ (í•œê¸€ + ì˜ì–´)
                                    city_pattern = '|'.join(list(city_mapping.keys()) + 
                                                            ['seoul', 'busan', 'incheon', 'daegu', 'daejeon', 
                                                             'gwangju', 'jeju', 'jeonju', 'tokyo', 'osaka', 
                                                             'beijing', 'shanghai', 'new york', 'london', 'paris',
                                                             'berlin', 'madrid', 'rome', 'moscow', 'bangkok', 
                                                             'singapore', 'sydney', 'melbourne', 'toronto', 
                                                             'vancouver', 'los angeles', 'chicago', 'washington', 
                                                             'boston', 'dubai', 'hong kong'])
                                    
                                    city_match = re.search(f'({city_pattern})', user_input, re.IGNORECASE)
                                    
                                    if city_match:
                                        matched_city = city_match.group(1)
                                        # í•œê¸€ì´ë©´ ì˜ì–´ë¡œ ë³€í™˜, ì˜ì–´ë©´ capitalize
                                        city_name = city_mapping.get(matched_city, matched_city.title())
                                        logger.info(f"ğŸŒ ì •ê·œí‘œí˜„ì‹ ë§¤ì¹­: {matched_city} â†’ {city_name}")
                                    else:
                                        # ğŸ¤– AI ëª¨ë¸ì„ ì‚¬ìš©í•œ ë„ì‹œëª… ì¶”ì¶œ (í´ë°±)
                                        logger.info("ğŸ¤– ì •ê·œí‘œí˜„ì‹ ì‹¤íŒ¨ - AI ëª¨ë¸ë¡œ ë„ì‹œëª… ì¶”ì¶œ ì‹œë„")
                                        try:
                                            extraction_prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ë„ì‹œëª…ì„ ì¶”ì¶œí•˜ê³  ì˜ì–´ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
ì§ˆë¬¸: "{user_input}"

ë„ì‹œëª…ì´ ìˆìœ¼ë©´ ì˜ì–´ ë„ì‹œëª…ë§Œ ì¶œë ¥í•˜ì„¸ìš”. (ì˜ˆ: Seoul, Paris, Tokyo)
ë„ì‹œëª…ì´ ì—†ìœ¼ë©´ "Seoul"ì„ ì¶œë ¥í•˜ì„¸ìš”.
ì¶œë ¥ í˜•ì‹: ë„ì‹œëª…ë§Œ (ì¶”ê°€ ì„¤ëª… ì—†ì´)"""
                                            
                                            temp_model = genai.GenerativeModel("gemini-2.0-flash-exp")
                                            ai_response = temp_model.generate_content(extraction_prompt).text.strip()
                                            
                                            # AI ì‘ë‹µì—ì„œ ë„ì‹œëª…ë§Œ ì¶”ì¶œ (ì²« ë‹¨ì–´ ë˜ëŠ” ì²« ì¤„)
                                            city_name = ai_response.split('\n')[0].split()[0].strip()
                                            
                                            # ìœ íš¨ì„± ê²€ì‚¬ (ì•ŒíŒŒë²³ê³¼ ê³µë°±ë§Œ í—ˆìš©)
                                            if not re.match(r'^[A-Za-z\s]+$', city_name):
                                                city_name = "Seoul"
                                            
                                            logger.info(f"ğŸ¤– AI ì¶”ì¶œ ì„±ê³µ: {ai_response} â†’ {city_name}")
                                        except Exception as e:
                                            logger.error(f"âŒ AI ë„ì‹œëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                                            city_name = "Seoul"  # ìµœì¢… ê¸°ë³¸ê°’
                                    
                                    # ë‚´ì¼ ë‚ ì”¨ vs í˜„ì¬ ë‚ ì”¨
                                    if "ë‚´ì¼" in query_lower or "tomorrow" in query_lower:
                                        weather_result = weather_api.get_forecast_by_day(city_name, 1)
                                        logger.info(f"â˜€ï¸ OpenWeatherMap APIë¡œ ë‚´ì¼ ë‚ ì”¨ ì¡°íšŒ: {city_name}")
                                    else:
                                        weather_result = weather_api.get_city_weather(city_name)
                                        logger.info(f"â˜€ï¸ OpenWeatherMap APIë¡œ í˜„ì¬ ë‚ ì”¨ ì¡°íšŒ: {city_name}")
                                    
                                    # ë‚ ì”¨ API ì‹¤íŒ¨ ì‹œ None ë°˜í™˜ (í´ë°± ì²˜ë¦¬)
                                    if weather_result is None:
                                        logger.warning(f"âš ï¸ OpenWeatherMap API ì‹¤íŒ¨, ë„¤ì´ë²„ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±")
                                
                                except Exception as e:
                                    logger.error(f"âŒ ë‚ ì”¨ API ì˜¤ë¥˜: {e}")
                                    weather_result = None
                    
                    # âœ¨ ì›¹ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ íŒë‹¨ ë° ì‹¤í–‰ (ë‚ ì”¨ API ì‹¤íŒ¨ ì‹œ í´ë°±)
                    search_context = ""
                    if st.session_state.api_manager:
                        try:
                            web_search_api = st.session_state.api_manager['apis']['web_search']
                            # Prioritize F1 intent: if user asks about F1 standings, skip web search
                            try:
                                f1_intent_check = detect_f1_intent(user_input)
                            except Exception as e:
                                logger.debug(f"F1 intent pre-check error: {e}")
                                f1_intent_check = None

                            if f1_intent_check and f1_intent_check.get("intent") == "f1_rank":
                                need_search = False
                                reason = "f1_intent"
                                logger.info("â­ï¸ F1 ì¸í…íŠ¸ ê°ì§€: ì›¹ ê²€ìƒ‰ ìƒëµ")
                            else:
                                # follow-up detection: prefer stored F1 context when user refers
                                # to the previous table/result (examples: 'ì—¬ê¸°ì„œ', 'ì´ í‘œ', 'ì´ ê²°ê³¼',
                                # 'based on this', 'from this list', 'ì •ë¦¬', 'top5' etc.). Also
                                # if the user input is short and we have a recent table, assume
                                # follow-up intent.
                                last_md = st.session_state.get("last_f1_table_md")
                                is_followup = False
                                if last_md:
                                    u = user_input.lower()
                                    # anaphora / reference patterns (KO/EN/ES)
                                    ref_patterns = [
                                        r"\b(ì—¬ê¸°ì„œ|ì´ í‘œ|ì´ ê²°ê³¼|ì´ ëª©ë¡|ì´ ìˆœìœ„|ì´ ë°ì´í„°|ì´ ë‚´ìš©|ì—¬ê¸°|ì§€ê¸ˆ ì—¬ê¸°)\b",
                                        r"\b(based on this|from this list|this table|this list|this result|from this)\b",
                                        r"\b(top5|top 5|top|ìƒìœ„|ìƒìœ„ê¶Œ|ì •ë¦¬|ìš”ì•½|ì •ë¦¬í•´|ì •ë¦¬í•´ì¤˜|ìš”ì•½í•´|ìš”ì•½í•´ì¤˜)\b",
                                        r"\b(quien|quiÃ©n|resumen|top)\b",
                                    ]
                                    for pat in ref_patterns:
                                        if re.search(pat, u):
                                            is_followup = True
                                            break

                                    # also consider short/clarifying follow-ups (< 60 chars)
                                    if not is_followup and len(u.strip()) <= 60:
                                        # if question words or pronouns present, treat as follow-up
                                        if re.search(r"\b(ëˆ„êµ¬|ì–´ë–¤|ëˆ„ê°€|ëª‡|how many|who|which|where|ì–´ë””|ì–¸ì œ|ì§€ê¸ˆ)\b", u):
                                            is_followup = True

                                if last_md and is_followup:
                                    need_search = False
                                    reason = "f1_context_followup"
                                    search_context = last_md
                                    logger.info("â­ï¸ F1 follow-up detected: using last F1 context as search_context")
                                else:
                                    # âœ¨ ê°œì„ ëœ should_search() ë©”ì„œë“œì— ê²€ìƒ‰ íŒë‹¨ ìœ„ì„
                                    # ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œìœ¼ë¡œ ì‹¤ì‹œê°„ ì •ë³´ í•„ìš”ì„± ìë™ íŒë‹¨
                                    need_search, reason = web_search_api.should_search(user_input)

                            
                            # ë‚ ì”¨ ì¿¼ë¦¬ì´ê³  OpenWeatherMap APIê°€ ì„±ê³µí•œ ê²½ìš° ì›¹ ê²€ìƒ‰ ìƒëµ
                            if weather_result is not None and ("ë‚ ì”¨" in user_input.lower() or "weather" in user_input.lower()):
                                need_search = False
                                reason = "ë‚ ì”¨ API ì„±ê³µ (ì›¹ ê²€ìƒ‰ ìƒëµ)"
                                logger.info(f"â­ï¸ {reason}")
                            # ë‚ ì”¨ ì¿¼ë¦¬ì´ê³  OpenWeatherMap APIê°€ ì‹¤íŒ¨í•œ ê²½ìš° ê°•ì œ ê²€ìƒ‰
                            elif weather_result is None and ("ë‚ ì”¨" in user_input.lower() or "weather" in user_input.lower()):
                                need_search = True
                                reason = "ë‚ ì”¨ API í´ë°±"
                            
                            if need_search:
                                status.update(label="ğŸ” ìµœì‹  ì •ë³´ ê²€ìƒ‰ ì¤‘...")
                                logger.info(f"ğŸ” ì›¹ ê²€ìƒ‰ ì‹¤í–‰: {reason}")
                                search_result = web_search_api.search_and_create_context(
                                    user_input, 
                                    st.session_state
                                )
                                
                                # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€
                                if not search_result.startswith("ê²€ìƒ‰ì´ í•„ìš”í•˜ì§€ ì•ŠìŒ"):
                                    search_context = search_result
                                    logger.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(search_result)} chars")
                                    # ë””ë²„ê·¸: ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
                                    preview = search_result[:200] + "..." if len(search_result) > 200 else search_result
                                    logger.info(f"ğŸ“„ ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:\n{preview}")
                            else:
                                logger.info(f"â­ï¸ ê²€ìƒ‰ ë¶ˆí•„ìš”: {reason}")
                        except Exception as e:
                            logger.error(f"âŒ ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                            # ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œì—ë„ ì¼ë°˜ ëŒ€í™”ëŠ” ê³„ì† ì§„í–‰
                    
                    # ë‚ ì”¨ API ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì§ì ‘ ì‘ë‹µìœ¼ë¡œ ì‚¬ìš© (ê²€ìƒ‰ ë¶ˆí•„ìš”)
                    if weather_result:
                        response = weather_result
                        st.session_state.chat_history.append({"role": "user", "parts": [user_input]})
                        st.session_state.chat_history.append({"role": "model", "parts": [response]})
                        logger.info("âœ… ë‚ ì”¨ API ì‘ë‹µ ì‚¬ìš© (ê²€ìƒ‰ ìƒëµ)")
                    # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¨¼ì € ë³´ì—¬ì£¼ê³  ëª¨ë¸ì—ê²Œ ê°„ë‹¨í•œ ìš”ì•½ë§Œ ìš”ì²­
                    elif search_context:
                        status.update(label="ğŸ“ ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬ ì¤‘...")
                        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë¨¼ì € í‘œì‹œ (ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ)
                        with st.chat_message("assistant"):
                            # ê²€ìƒ‰ ê²°ê³¼ ì§ì ‘ ì¶œë ¥
                            st.markdown(search_context)
                        
                        # ëª¨ë¸ì—ê²Œ ê°„ë‹¨í•œ ìš”ì•½ë§Œ ìš”ì²­ (ì„ íƒì )
                        summary_prompt = f"""ì‚¬ìš©ìì˜ ì§ˆë¬¸: "{user_input}"

ìœ„ì˜ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ ë‹µë³€ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì£¼ì˜ì‚¬í•­:
1. ê²€ìƒ‰ ê²°ê³¼ì˜ ë²ˆí˜¸ë‚˜ í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”
2. ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì •ë³´ë§Œ ì¶”ì¶œí•´ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”
3. ìˆ«ì, ë‚ ì§œ, êµ¬ì²´ì ì¸ ì •ë³´ëŠ” í¬í•¨í•´ì£¼ì„¸ìš”
4. ìì—°ìŠ¤ëŸ¬ìš´ í•œ ë¬¸ì¥ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”"""
                        
                        chat_session = response_model.start_chat(history=st.session_state.chat_history)
                        try:
                            summary_response = chat_session.send_message(summary_prompt).text
                            # ìš”ì•½ì€ ë³„ë„ ë©”ì‹œì§€ë¡œ ì¶”ê°€
                            with st.chat_message("assistant"):
                                st.markdown(f"\n\nğŸ’¡ **í•µì‹¬ ë‹µë³€**\n\n{summary_response}")
                            
                            # íˆìŠ¤í† ë¦¬ì—ëŠ” ê²€ìƒ‰ ê²°ê³¼ + ìš”ì•½ì„ í•¨ê»˜ ì €ì¥
                            full_response = f"{search_context}\n\nğŸ’¡ **í•µì‹¬ ìš”ì•½**\n{summary_response}"
                            st.session_state.chat_history.append({"role": "user", "parts": [user_input]})
                            st.session_state.chat_history.append({"role": "model", "parts": [full_response]})
                            logger.info("âœ… ê²€ìƒ‰ ê²°ê³¼ + ìš”ì•½ ì™„ë£Œ")
                            response = full_response  # ì €ì¥ìš©
                        except Exception as e:
                            logger.error(f"ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
                            # ìš”ì•½ ì‹¤íŒ¨ ì‹œ ê²€ìƒ‰ ê²°ê³¼ë§Œ ì €ì¥
                            response = search_context
                            st.session_state.chat_history.append({"role": "user", "parts": [user_input]})
                            st.session_state.chat_history.append({"role": "model", "parts": [response]})
                    else:
                        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¨¼ì € F1 ê´€ë ¨ ì¸í…íŠ¸ì¸ì§€ í™•ì¸
                        try:
                            f1_intent = detect_f1_intent(user_input)
                        except Exception as e:
                            logger.warning(f"F1 intent detection error: {e}")
                            f1_intent = None

                        if f1_intent and f1_intent.get("intent") == "f1_rank":
                            # year ì¶”ì¶œ ë˜ëŠ” ê¸°ë³¸ í˜„ì¬ ì—°ë„
                            year = f1_intent.get("year") or datetime.now().year

                            # ìºì‹œ í™•ì¸ (Supabase ì‚¬ìš© ì—¬ë¶€ëŠ” envë¡œ ê²°ì •)
                            cached = None
                            try:
                                use_supabase = os.environ.get("USE_SUPABASE", "0") == "1"
                                ttl = int(os.environ.get("F1_CACHE_TTL", "3600"))
                                if use_supabase and is_cache_fresh_supabase(year, ttl):
                                    cached = load_cached_drivers_supabase(year)
                            except Exception as e:
                                logger.debug(f"F1 cache check error: {e}")

                            if cached and isinstance(cached, dict) and cached.get("rows"):
                                rows = cached.get("rows")
                                meta = cached.get("meta", {})
                                source = "supabase_cache"
                            else:
                                # ë¼ì´ë¸Œë¡œ ê°€ì ¸ì˜¤ê¸°
                                result = fetch_drivers(year)
                                if not result.get("success"):
                                    response = result.get("error", "âŒ F1 ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                                    st.session_state.chat_history.append({"role": "user", "parts": [user_input]})
                                    st.session_state.chat_history.append({"role": "model", "parts": [response]})
                                    st.session_state.messages.append({"role": "assistant", "content": response})
                                    save_current_session()
                                    # don't rerun here; set final_input to None to skip model flow
                                    final_input = None

                                rows = result.get("rows", [])
                                meta = result.get("meta", {})
                                source = meta.get("source", "live")

                                # ìºì‹œì— ì €ì¥ ì‹œë„
                                try:
                                    if os.environ.get("USE_SUPABASE", "0") == "1":
                                        save_cached_drivers_supabase(year, rows, meta)
                                except Exception as e:
                                    logger.debug(f"F1 cache save error: {e}")

                            # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°”ë¡œ ì¶œë ¥
                            try:
                                headers = rows[0] if rows else []
                                data_rows = rows[1:] if len(rows) > 1 else []
                                out_lang = detect_response_language(user_input, st.session_state.system_language)
                                localized_headers = localize_headers(headers, out_lang)
                                df = pd.DataFrame(data_rows, columns=localized_headers)

                                # ì‚¬ìš©ìì—ê²Œ ë°”ë¡œ í‘œì‹œ
                                title_map = {"ko": f"F1 {year} ìˆœìœ„", "en": f"F1 {year} standings", "es": f"ClasificaciÃ³n F1 {year}"}
                                title = title_map.get(out_lang, title_map["en"])
                                # build markdown table for display and storage (no extra index column)
                                headers_md = localized_headers
                                md_lines = []
                                md_lines.append(f"**{title}**")
                                md_lines.append("")
                                md_lines.append("| " + " | ".join(headers_md) + " |")
                                md_lines.append("|" + "|".join(["---"] * len(headers_md)) + "|")
                                for r in data_rows:
                                    cells = [str(c) if c is not None else "" for c in r[:len(headers_md)]]
                                    md_lines.append("| " + " | ".join(cells) + " |")
                                markdown_table = "\n".join(md_lines)

                                # save last F1 context for follow-up questions
                                try:
                                    st.session_state['last_f1_table_md'] = markdown_table
                                    st.session_state['last_f1_year'] = year
                                    st.session_state['last_f1_table_time'] = datetime.now().isoformat()
                                except Exception:
                                    pass

                                # Build a small plain-text Top5 summary and show full table inside an expander
                                try:
                                    # try to find relevant column indices from raw headers
                                    def _col_index(names, keywords, default):
                                        for kw in keywords:
                                            for i, h in enumerate(headers):
                                                if kw in h.lower():
                                                    return i
                                        return default

                                    driver_idx = _col_index(headers, ["driver", "name"], 1)
                                    team_idx = _col_index(headers, ["team", "constructor"], 3)
                                    points_idx = _col_index(headers, ["pt", "points", "pts"], 4)

                                    top5 = data_rows[:5]
                                    summary_lines = []
                                    for r in top5:
                                        try:
                                            drv = str(r[driver_idx])
                                        except Exception:
                                            drv = ""
                                        try:
                                            tm = str(r[team_idx])
                                        except Exception:
                                            tm = ""
                                        try:
                                            pts = str(r[points_idx])
                                        except Exception:
                                            pts = ""
                                        summary_lines.append(f"- {drv} ({tm}) â€” {pts} pts")

                                    summary_text = "\n".join(summary_lines)

                                except Exception as e:
                                    logger.debug(f"Top5 build error: {e}")
                                    summary_text = "(ìš”ì•½ ìƒì„± ì‹¤íŒ¨)"

                                # show as plain chat message + expander for full table
                                with st.chat_message("assistant"):
                                    st.markdown(f"**{title}**\n\n{summary_text}")
                                    with st.expander(get_text("view_full_table", out_lang) if 'get_text' in globals() else "ì „ì²´ ìˆœìœ„ ë³´ê¸°"):
                                        st.markdown(markdown_table)
                                    st.caption(f"{year}")

                                # íˆìŠ¤í† ë¦¬ ì €ì¥
                                st.session_state.chat_history.append({"role": "user", "parts": [user_input]})
                                st.session_state.chat_history.append({"role": "model", "parts": [f"Displayed F1 standings for {year} ({source})"]})

                                # Save a markdown version of the table into chat history so DB stores it
                                try:
                                    # build markdown table
                                    headers_md = localized_headers
                                    md_lines = []
                                    md_lines.append("| " + " | ".join(headers_md) + " |")
                                    md_lines.append("|" + "|".join(["---"] * len(headers_md)) + "|")
                                    for r in data_rows:
                                        # ensure r has the same length as headers
                                        cells = [str(c) if c is not None else "" for c in r[:len(headers_md)]]
                                        md_lines.append("| " + " | ".join(cells) + " |")
                                    markdown_table = "\n".join(md_lines)
                                    assistant_content = f"**{title}**\n\n{markdown_table}"
                                except Exception as e:
                                    logger.debug(f"F1 markdown build error: {e}")
                                    assistant_content = title

                                st.session_state.messages.append({"role": "assistant", "content": assistant_content})
                                save_current_session()
                                # avoid rerun which can clear transient UI; skip further model processing
                                final_input = None
                                response = title
                            except Exception as e:
                                logger.error(f"F1 display error: {e}")
                                # ì‹¤íŒ¨í•˜ë©´ ì¼ë°˜ ëª¨ë¸ ì²˜ë¦¬ë¡œ í´ë°±
                                final_input = user_input
                        else:
                            # F1 ì¸í…íŠ¸ê°€ ì•„ë‹ˆë©´ ì¼ë°˜ ëª¨ë¸ ì²˜ë¦¬
                            final_input = user_input
                    
                        if final_input is not None:
                            chat_session = response_model.start_chat(history=st.session_state.chat_history)
                            try:
                                status.update(label=get_text("processing_response", response_language))
                                response = chat_session.send_message(final_input).text
                                st.session_state.chat_history = chat_session.history
                            except Exception as e:
                                logger.error(f"Google Generative AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {e}")
                                response = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì„œë¹„ìŠ¤ì— ë¬¸ì œê°€ ìˆì–´ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        else:
                            # final_input is None -> F1 handler already handled the response; skip model call
                            logger.info("F1 handled locally; skipping model call")
                    
                    status.update(label=get_text("processing_complete", response_language), state="complete")

            st.session_state.messages.append({"role": "assistant", "content": response})
            st.session_state.uploaded_images = []
            st.session_state.uploaded_pdf_file = None
            save_current_session()
            # Only trigger a rerun if we actually invoked the model flow.
            if not ('final_input' in locals() and final_input is None):
                st.rerun()
    
    # Footer (ë‹¤êµ­ì–´ ì ìš©)
    st.markdown(f"""
    <div class="footer">
        <div style="display: flex; justify-content: center; align-items: center; gap: 0.5rem; flex-wrap: wrap; font-size: 0.8rem;">
            <span>{get_text("powered_by", lang)}</span>
            <span style="background: linear-gradient(135deg, #6c63ff, #4ecdc4); 
                         -webkit-background-clip: text; 
                         -webkit-text-fill-color: transparent; 
                         font-weight: 600;">Gemini AI</span>
            <span>x</span>
            <span style="background: linear-gradient(135deg, #ff6b6b, #feca57); 
                         -webkit-background-clip: text; 
                         -webkit-text-fill-color: transparent; 
                         font-weight: 600;">Streamlit</span>
        </div>
    </div>
    """, unsafe_allow_html=True)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    debug_timings = os.environ.get("STREAMLIT_DEBUG_LOAD_TIMINGS", "0") == "1"

    # (early-render indicator removed)

    if debug_timings:
        t_start = time.perf_counter()
    initialize_session_state()
    if debug_timings:
        t_after_init = time.perf_counter()

    # NOTE: Defer genai configuration until it's actually needed (user logged in
    # and chat dashboard is shown). This avoids any genai-related initialization
    # during the initial render/login page which can delay mobile cold starts.

    if not st.session_state.is_logged_in:
        if debug_timings:
            logger.info(f"TIMING: initialize_session_state took {t_after_init - t_start:.4f}s")
        show_login_page()
    else:
        # Configure genai lazily now that user is authenticated and chat UI will be rendered
        if debug_timings:
            t_before_genai = time.perf_counter()
        ensure_genai_configured()
        
        # Initialize API manager (web search, etc.) if not already done
        if "api_manager" not in st.session_state:
            try:
                api_data = initialize_apis()
                st.session_state.api_manager = api_data
                logger.info("âœ… API Manager ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ API Manager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                st.session_state.api_manager = None
        
        if debug_timings:
            t_after_genai = time.perf_counter()
            logger.info(f"TIMING: genai configuration took {t_after_genai - t_before_genai:.4f}s")
            logger.info(f"TIMING: total pre-render time {(time.perf_counter() - t_start):.4f}s")
        show_chat_dashboard()

if __name__ == "__main__":
    main()